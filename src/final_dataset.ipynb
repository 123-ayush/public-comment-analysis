{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5713b837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Searching for CSV files...\n",
      " Found 7 CSV files:\n",
      " - C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\pdf_extracted_comments.csv\n",
      " - C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\pdf_filtered_200.csv\n",
      " - C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\playstore_policy_reviews.csv\n",
      " - C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\policy_comment_dataset_500.csv\n",
      " - C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\policy_comment_dataset_500_cleaned.csv\n",
      " - C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\short_comments_dataset.csv\n",
      " - C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\synthetic_policy_comments_1200.csv\n",
      "\n",
      " Merging files...\n",
      "\n",
      " Removing duplicates...\n",
      " Resetting index...\n",
      "\n",
      " Merging Completed!\n",
      " Saved merged file as: C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\merged_raw_dataset.csv\n",
      " Final Row Count: 5373\n",
      " Columns: ['file_name', 'comment_text', 'stance_label', 'word_count', 'policy_domain', 'app_name', 'package_name', 'rating', 'policy_id', 'policy_title', 'domain', 'state', 'district', 'source_type', 'source_name', 'respondent_type', 'sentiment_label', 'cleaned_comment_text']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# ------------------------------------\n",
    "# UPDATE THIS PATH TO YOUR FOLDER\n",
    "# ------------------------------------\n",
    "DATASET_PATH = r\"C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\"   # folder where all CSVs are stored\n",
    "OUTPUT_FILE = r\"C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\merged_raw_dataset.csv\"\n",
    "\n",
    "print(\" Searching for CSV files...\")\n",
    "csv_files = glob.glob(DATASET_PATH + \"/*.csv\")\n",
    "\n",
    "print(f\" Found {len(csv_files)} CSV files:\")\n",
    "for f in csv_files:\n",
    "    print(\" -\", f)\n",
    "\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# ------------------------------------\n",
    "# STANDARDIZE COLUMN NAMES\n",
    "# ------------------------------------\n",
    "def normalize_columns(df):\n",
    "    df = df.rename(columns={\n",
    "        'comment': 'comment_text',\n",
    "        'comments': 'comment_text',\n",
    "        'text': 'comment_text',\n",
    "        'review_text': 'comment_text',\n",
    "        'stance': 'stance_label',\n",
    "        'label': 'stance_label',\n",
    "        'sentiment': 'stance_label'\n",
    "    })\n",
    "\n",
    "    # Ensure essential columns exist\n",
    "    if \"comment_text\" not in df.columns:\n",
    "        df[\"comment_text\"] = None\n",
    "\n",
    "    if \"stance_label\" not in df.columns:\n",
    "        df[\"stance_label\"] = None\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# READ AND MERGE ALL FILES\n",
    "# ------------------------------------\n",
    "print(\"\\n Merging files...\")\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        df = normalize_columns(df)\n",
    "\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error reading {file}: {e}\")\n",
    "\n",
    "print(\"\\n Removing duplicates...\")\n",
    "merged_df.drop_duplicates(subset=[\"comment_text\"], inplace=True)\n",
    "\n",
    "print(\" Resetting index...\")\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ------------------------------------\n",
    "# SAVE MERGED FILE\n",
    "# ------------------------------------\n",
    "merged_df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"\\n Merging Completed!\")\n",
    "print(f\" Saved merged file as: {OUTPUT_FILE}\")\n",
    "print(f\" Final Row Count: {len(merged_df)}\")\n",
    "print(\" Columns:\", list(merged_df.columns))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
