{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540a02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading dataset: C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\merged_raw_dataset.csv\n",
      "Initial shape: (5373, 18)\n",
      "Initial columns: ['file_name', 'comment_text', 'stance_label', 'word_count', 'policy_domain', 'app_name', 'package_name', 'rating', 'policy_id', 'policy_title', 'domain', 'state', 'district', 'source_type', 'source_name', 'respondent_type', 'sentiment_label', 'cleaned_comment_text']\n",
      " Using text column: comment_text\n",
      " Using label column: stance_label\n",
      " Cleaning text...\n",
      "After cleaning: (5267, 18)\n",
      " Normalizing labels...\n",
      "After label cleaning: (4774, 18)\n",
      "Label distribution:\n",
      " stance_label\n",
      "neutral    3725\n",
      "against     539\n",
      "for         510\n",
      "Name: count, dtype: int64\n",
      "Sampling down from 4774 â†’ 2000 (stratified)\n",
      "Final 2000 shape: (2000, 18)\n",
      "Final distribution:\n",
      " stance_label\n",
      "neutral    1560\n",
      "against     226\n",
      "for         214\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸŽ‰ DONE!\n",
      "Full cleaned dataset saved as: C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\final_cleaned_dataset.csv\n",
      "2000-row cleaned dataset saved as: C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\final_cleaned_dataset_2000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush Ahlawat\\AppData\\Local\\Temp\\ipykernel_17012\\3187697776.py:136: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_2000 = df.groupby(\"stance_label\", group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "INPUT_PATH = r\"C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\merged_raw_dataset.csv\"\n",
    "OUTPUT_PATH_FULL = r\"C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\final_cleaned_dataset.csv\"\n",
    "OUTPUT_PATH_2000 = r\"C:\\Users\\Ayush Ahlawat\\OneDrive\\Documents\\Public Comment Analysis\\public-comment-analysis\\dataset\\final_cleaned_dataset_2000.csv\"\n",
    "\n",
    "print(\" Loading dataset:\", INPUT_PATH)\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "print(\"Initial shape:\", df.shape)\n",
    "print(\"Initial columns:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "possible_text_cols = [\"comment_text\", \"comment\", \"text\", \"review\", \"review_text\", \"comments\"]\n",
    "text_col = None\n",
    "for col in df.columns:\n",
    "    if col.lower() in possible_text_cols:\n",
    "        text_col = col\n",
    "        break\n",
    "if text_col is None:\n",
    "    text_col = df.columns[0]\n",
    "\n",
    "print(\" Using text column:\", text_col)\n",
    "\n",
    "possible_label_cols = [\"stance_label\", \"sentiment\", \"label\", \"stance\", \"polarity\"]\n",
    "label_col = None\n",
    "for col in df.columns:\n",
    "    if col.lower() in possible_label_cols:\n",
    "        label_col = col\n",
    "        break\n",
    "\n",
    "if label_col:\n",
    "    print(\" Using label column:\", label_col)\n",
    "else:\n",
    "    print(\" No label column found â€” creating empty one.\")\n",
    "    df[\"stance_label\"] = np.nan\n",
    "    label_col = \"stance_label\"\n",
    "\n",
    "df = df.rename(columns={text_col: \"comment_text\", label_col: \"stance_label\"})\n",
    "\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"\n",
    "         u\"\\U0001F300-\\U0001F5FF\"\n",
    "         u\"\\U0001F680-\\U0001F6FF\"\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def clean_text(x):\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    x = str(x)\n",
    "\n",
    "    x = re.sub(r\"http\\S+|www\\S+\", \"\", x)\n",
    "\n",
    "    x = emoji_pattern.sub(r\"\", x)\n",
    "\n",
    "    x = re.sub(r\"[^\\x00-\\x7F]+\",\" \", x)\n",
    "\n",
    "    x = re.sub(r\"[^a-zA-Z0-9@#'\\s]\", \" \", x)\n",
    "\n",
    "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "\n",
    "    return x.lower()\n",
    "\n",
    "print(\" Cleaning text...\")\n",
    "df[\"comment_text\"] = df[\"comment_text\"].apply(clean_text)\n",
    "\n",
    "\n",
    "df = df[df[\"comment_text\"].str.strip() != \"\"]\n",
    "df = df.drop_duplicates(subset=[\"comment_text\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"After cleaning:\", df.shape)\n",
    "\n",
    "\n",
    "def normalize_label(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).lower().strip()\n",
    "\n",
    "    positive = [\"for\", \"yes\", \"pro\", \"support\", \"positive\", \"agree\"]\n",
    "    negative = [\"against\", \"no\", \"anti\", \"oppose\", \"negative\", \"disagree\"]\n",
    "    neutral = [\"neutral\", \"none\", \"mixed\", \"undecided\"]\n",
    "\n",
    "    if s in positive:\n",
    "        return \"for\"\n",
    "    if s in negative:\n",
    "        return \"against\"\n",
    "    if s in neutral:\n",
    "        return \"neutral\"\n",
    "\n",
    "    # keyword inference\n",
    "    if any(w in s for w in [\"support\", \"good\", \"benefit\", \"positive\"]):\n",
    "        return \"for\"\n",
    "    if any(w in s for w in [\"oppose\", \"bad\", \"concern\", \"negative\"]):\n",
    "        return \"against\"\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "print(\" Normalizing labels...\")\n",
    "df[\"stance_label\"] = df[\"stance_label\"].apply(normalize_label)\n",
    "\n",
    "# Remove unlabeled rows\n",
    "df = df.dropna(subset=[\"stance_label\"])\n",
    "df = df[df[\"stance_label\"].isin([\"for\", \"against\", \"neutral\"])]\n",
    "\n",
    "print(\"After label cleaning:\", df.shape)\n",
    "print(\"Label distribution:\\n\", df[\"stance_label\"].value_counts())\n",
    "\n",
    "\n",
    "TARGET = 2000\n",
    "current = len(df)\n",
    "\n",
    "if current >= 2100:\n",
    "    print(f\"Sampling down from {current} â†’ {TARGET} (stratified)\")\n",
    "    df_2000 = df.groupby(\"stance_label\", group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=TARGET/current, random_state=42)\n",
    "    )\n",
    "    df_2000 = df_2000.sample(n=TARGET, random_state=42).reset_index(drop=True)\n",
    "\n",
    "elif current < 1800:\n",
    "    print(f\"Dataset too small ({current}), upsampling â†’ {TARGET}\")\n",
    "    needed = TARGET - current\n",
    "    df_2000 = pd.concat([df, df.sample(n=needed, replace=True, random_state=42)])\n",
    "    df_2000 = df_2000.reset_index(drop=True)\n",
    "\n",
    "else:\n",
    "    print(f\"Dataset acceptable ({current}), sampling to exactly {TARGET}\")\n",
    "    df_2000 = df.sample(n=TARGET, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Final 2000 shape:\", df_2000.shape)\n",
    "print(\"Final distribution:\\n\", df_2000[\"stance_label\"].value_counts())\n",
    "\n",
    "\n",
    "df.to_csv(OUTPUT_PATH_FULL, index=False)\n",
    "df_2000.to_csv(OUTPUT_PATH_2000, index=False)\n",
    "\n",
    "print(\"\\nðŸŽ‰ DONE!\")\n",
    "print(\"Full cleaned dataset saved as:\", OUTPUT_PATH_FULL)\n",
    "print(\"2000-row cleaned dataset saved as:\", OUTPUT_PATH_2000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
